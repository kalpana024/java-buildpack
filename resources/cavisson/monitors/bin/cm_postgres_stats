################################################################################
## Name    : cm_postgres_stats
## Purpose : This is a standard monitor to get postgres statistics
## Option  : 'Run Everytime' & 'Run Once'
## GDF     : cm_postgres_stats.gdf in netstorm machine ($NS_WDIR/sys)
## Keyword :
##           STANDARD_MONITOR 127.0.0.1 NSAppliance_PostgresStats PostgresStats -i <Interval> -u <USER> -p <password> -H <HOST/IP> -P <PORT> 
##           -d <Database-Name> -t <trace level>
##
##           Example: 
##           STANDARD_MONITOR 127.0.0.1 NSAppliance_PostgresStats PostgresStats -u "root" -d "postgres"
##
## Date    : Wednesday, 19 Nov 2014
################################################################################

#Set CAV_MON_HOME to allow testing from command line
if [ "X$CAV_MON_HOME" = "X" ]; then
  if [ -d /opt/cavisson/monitors ];then
    export CAV_MON_HOME="/opt/cavisson/monitors"
  elif [ -d ~/cavisson/monitors ];then
    export CAV_MON_HOME=~/cavisson/monitors
  else
    echo "CAV_MON_HOME is not set"
    exit -1
  fi
fi

 . $CAV_MON_HOME/bin/ns_check_monitor_func.sh

lib_set_ps_cmd

trace_log()
{
  TRACE_LEVEL=$1

  if [ $TRACE -lt $TRACE_LEVEL ]; then
    return
  else
    echo `date +'%F %X'`"|" $2 >>$TRACE_LOG_FILE

    #file rollback
    TL_FILE_SIZE=`ls -l $TRACE_LOG_FILE  | awk -F' ' '{print $5}'`
    if [ $TL_FILE_SIZE -gt 104857600 ]; then  #100 MB
      mv $TRACE_LOG_FILE ${TRACE_LOG_FILE}.prev
    fi
  fi

  if [ "X$3" != "X" ]; then
    $3 >>$TRACE_LOG_FILE
  fi
}

set_up_env() 
{
  IS_FIRST_SAMPLE=1
  INTERVAL=$MON_FREQUENCY
  HOST="127.0.0.1"

  #Can validate from /etc/services : 
  #postgresql      5432/tcp        postgres        # PostgreSQL Database
  #postgresql      5432/udp        postgres
  PORT=5432

  USER=""
  PASSWORD=""
  DATABASE_NAME=""

  QUERY_ERR_FILE="$CAV_MON_TMP_DIR/cm_postgres_stats.err.$$"
  TRACE=2
}


set_error_and_trace_log_file()
{
  if [ "XX$CAV_MON_HOME" != "XX" ];then
    ERROR_LOG_FILE="$CAV_MON_HOME/logs/cm_postgres_stats__"$MON_TEST_RUN"_"$VECTOR_NAME"_error.log"
    TRACE_LOG_FILE="$CAV_MON_HOME/logs/cm_postgres_stats__"$MON_TEST_RUN"_"$VECTOR_NAME"_trace.log"
  else
    ERROR_LOG_FILE="/tmp/cm_postgres_stats_error_log.$$"
    TRACE_LOG_FILE="/tmp/cm_postgres_stats_trace_log.$$"
    error_log "CAV_MON_HOME is not exported, putting logs to /tmp/."
  fi
}

error_log()
{
  ns_log_event "Major" "$*"
  echo `date +'%F %X'`"|" $* >> $ERROR_LOG_FILE
}

make_query_psql()
{
  QUERY_FOR_DBID="select datid from pg_stat_database where datname = '$DATABASE_NAME';"
  QUERY_FOR_STATS="select numbackends, blks_read, xact_commit, blks_hit from pg_stat_database where datname = '$DATABASE_NAME';"
  QUERY_FOR_ACTIVE_CONN="select count(*) as active_conn from pg_stat_activity where current_query != '<IDLE>' and datname = '$DATABASE_NAME';"
  QUERY_FOR_LOCKS_CONSUMED="select count(*) AS num_locks from pg_locks;"

  # If total_checkpoint is 0 , divide by zero error occured. And now using case condition, this is prevented.    
  QUERY_FOR_CHECKPOINTS="SELECT seconds_since_start / total_checkpoints / 60 AS minutes_between_checkpoints FROM (SELECT EXTRACT(EPOCH FROM (now() - pg_postmaster_start_time())) AS seconds_since_start, (checkpoints_timed+checkpoints_req), CASE WHEN (checkpoints_timed+checkpoints_req) > 0 THEN (checkpoints_timed+checkpoints_req) ELSE 1 END AS total_checkpoints FROM pg_stat_bgwriter ) AS sub;"

  trace_log 1 "QUERY_FOR_DBID = '$QUERY_FOR_DBID', QUERY_FOR_STATS = '$QUERY_FOR_STATS', QUERY_FOR_ACTIVE_CONN = '$QUERY_FOR_ACTIVE_CONN', QUERY_FOR_LOCKS_CONSUMED = '$QUERY_FOR_LOCKS_CONSUMED', QUERY_FOR_CHECKPOINTS = '$QUERY_FOR_CHECKPOINTS'"
}


#DBID QUERY OUTPUT
#datid
#11921
set_dbid()
{
  QUERY_OUT=$(psql -h $HOST -p $PORT -U $USER $DATABASE_NAME --no-align --field-separator ',' --pset footer 2>>$QUERY_ERR_FILE <<+
$QUERY_FOR_DBID
;
+
)
  trace_log 1 "DBID Query Output = $QUERY_OUT"
  DBID=`echo "$QUERY_OUT" | tail -1`
  trace_log 1 "DBID = $DBID"
}

#Function to run database queries
run_query_psql()
{
  trace_log 2 "Running database queries..."

  #psql -H 127.0.0.1 -P 5432 -u netstorm test 
  QUERY_OUT=$(psql -h $HOST -p $PORT -U $USER $DATABASE_NAME --no-align --field-separator ' ' --pset footer 2>>$QUERY_ERR_FILE <<+
$QUERY_FOR_STATS
$QUERY_FOR_ACTIVE_CONN
$QUERY_FOR_LOCKS_CONSUMED
$QUERY_FOR_CHECKPOINTS
;
+
)
  trace_log 2 "QUERY_OUT = $QUERY_OUT"
}

#numbackends,blks_read,xact_commit,blks_hit
#2,2376,472,17969
#active_conn
#1
#num_locks
#2
#minutes_between_checkpoints
#3187.91201598838

process_data()
{
  trace_log 2 "Processing query output..."

  DATA_LINE=`echo "$QUERY_OUT" | grep "numbackends" -A 1 | tail -1`
  read NUM_BACKENDS BLKS_READ XACT_COMMIT BLKS_HIT <<< $(echo "$DATA_LINE")

  ACTIVE_CONN=`echo "$QUERY_OUT" | grep "active_conn" -A 1 | tail -1`
  LOCKS_CONSUMED=`echo "$QUERY_OUT" | grep "num_locks" -A 1 | tail -1`
  MIN_BW_CHECKPOINTS=`echo "$QUERY_OUT" | grep "minutes_between_checkpoints" -A 1 | tail -1`


  #Shared memory
  PID_RUNNING=0
  if [ "X$POSTGRES_PID" != "X" ]; then
    ps -p $POSTGRES_PID 1>/dev/null 2>/dev/null
    if [ $? -eq 0 ]; then
      PID_RUNNING=1
    fi
  fi  
  if [ "X$PID_RUNNING" = "X0" ]; then
    POSTGRES_PID=`ps -ef | grep postgres | grep "\-D" | awk '{print $2}'`
  fi
  SHR_MEM=`top -p $POSTGRES_PID -n1 -b | grep "PID" -A1 | tail -1 | awk '{print $7}'`

  #Shared memory unit may be 'g' or 'm'; no unit size is displayed in case of KB
  SHR_MEM_UNIT=`echo -n "$SHR_MEM" | tail -c -1`  #Get last char of shared memory size

  if [ "X$SHR_MEM_UNIT" = "Xg" ]; then 
    SHR_MEM=`echo -n "$SHR_MEM" | head -c -1` #Removing last char
    SHR_MEM=`awk -v "var1=$SHR_MEM" 'BEGIN{printf "%f", var1 * 1048576}'`  #Converting from GB to KB
  elif [ "X$SHR_MEM_UNIT" = "Xm" ]; then 
    SHR_MEM=`echo -n "$SHR_MEM" | head -c -1` #Removing last char
    SHR_MEM=`awk -v "var1=$SHR_MEM" 'BEGIN{printf "%f", var1 * 1024}'`  #Converting from MB to KB
  elif [ "X$SHR_MEM_UNIT" = "Xk" ]; then 
    SHR_MEM=`echo -n "$SHR_MEM" | head -c -1` #Removing last char
  fi

  trace_log 2 "DATA_LINE = '$DATA_LINE' NUM_BACKENDS = '$NUM_BACKENDS' BLKS_READ = '$BLKS_READ' XACT_COMMIT = 'XACT_COMMIT' BLKS_HIT = 'BLKS_HIT' ACTIVE_CONN = '$ACTIVE_CONN' LOCKS_CONSUMED = '$LOCKS_CONSUMED' MIN_BW_CHECKPOINTS = '$MIN_BW_CHECKPOINTS' POSTGRES_PID = '$POSTGRES_PID' SHR_MEM = '$SHR_MEM' SHR_MEM_UNIT = '$SHR_MEM_UNIT'"

}

display_data()
{
  trace_log 2 "Display data :"

  BLKS_WRITE=0  #TODO remove this , Do't have query rght now, hence showing '0'

  if [ $IS_FIRST_SAMPLE -eq 1 ]; then
    BLKS_READ_PER_MIN=0
    BLKS_WRITE_PER_MIN=0
    BLKS_HIT_PER_MIN=0
    XACT_COMMIT_PER_MIN=0
    IS_FIRST_SAMPLE=0
  else
    BLKS_READ_PER_MIN=`awk -v "var1=$BLKS_READ" -v "var2=$PREV_BLKS_READ" -v "var3=$INTERVAL_IN_MIN" 'BEGIN{printf "%f", (var1-var2)/var3}'`
    BLKS_WRITE_PER_MIN=`awk -v "var1=$BLKS_WRITE" -v "var2=$PREV_BLKS_WRITE" -v "var3=$INTERVAL_IN_MIN" 'BEGIN{printf "%f", (var1-var2)/var3}'`
    BLKS_HIT_PER_MIN=`awk -v "var1=$BLKS_HIT" -v "var2=$PREV_BLKS_HIT" -v "var3=$INTERVAL_IN_MIN" 'BEGIN{printf "%f", (var1-var2)/var3}'`
    XACT_COMMIT_PER_MIN=`awk -v "var1=$XACT_COMMIT" -v "var2=$PREV_XACT_COMMIT" -v "var3=$INTERVAL_IN_MIN" 'BEGIN{printf "%f", (var1-var2)/var3}'`
  fi


  #show data
  echo $NUM_BACKENDS $ACTIVE_CONN $BLKS_READ_PER_MIN $BLKS_WRITE_PER_MIN $LOCKS_CONSUMED $SHR_MEM $BLKS_HIT_PER_MIN $XACT_COMMIT_PER_MIN $MIN_BW_CHECKPOINTS

  #Save previous data
  PREV_BLKS_READ="$BLKS_READ"
  PREV_BLKS_WRITE="$BLKS_WRITE"
  PREV_BLKS_HIT="$BLKS_HIT"
  PREV_XACT_COMMIT="$XACT_COMMIT"

  trace_log 2 "BLKS_READ_PER_MIN = '$BLKS_READ_PER_MIN' BLKS_WRITE_PER_MIN = '$BLKS_WRITE_PER_MIN' BLKS_HIT_PER_MIN = '$BLKS_HIT_PER_MIN' XACT_COMMIT_PER_MIN = '$XACT_COMMIT_PER_MIN' IS_FIRST_SAMPLE = '$IS_FIRST_SAMPLE' PREV_BLKS_READ = '$PREV_BLKS_READ' PREV_BLKS_WRIT = '$PREV_BLKS_WRIT' PREV_BLKS_HIT = '$PREV_BLKS_HIT' PREV_XACT_COMMIT = '$PREV_XACT_COMMIT' INTERVAL_IN_MIN = '$INTERVAL_IN_MIN'"
}

check_and_remove_files()
{
  if [ -f $QUERY_ERR_FILE ]; then
    FILE_SIZE=`ls -l $QUERY_ERR_FILE | awk '{print $5}'`
    trace_log 2 "QUERY_ERR_FILE_SIZE = '$FILE_SIZE'"
    if [ $FILE_SIZE -eq 0 ]; then
      trace_log 2 "Removing file '$QUERY_ERR_FILE'"
      rm -f $QUERY_ERR_FILE
    elif [ "X$1" = "Xexit" ]; then
      trace_log 1 "Error occured in running query, Query file size = $FILE_SIZE, exiting ....."
      error_log "Error occured in running query, Query file size = $FILE_SIZE, exiting ....."
      exit 1
    fi
  fi
}

check_mandatory_options()
{
  trace_log 3 "Method check_mandatory_options called"
  
  if [ "X$USER" = "X" ];then
    Usage "USER name is mandatory"
  fi

  if [ "X$DATABASE_NAME" = "X" ];then
    Usage "DATABASE_NAME is mandatory"
  fi
}

calculate_sleep_interval()
{
  #calculate time in seconds till midnight
  CUR_TIME=$(date '+%s')
  MIDNIGHT_TIME=$(date -d 'tomorrow 00:00:00' '+%s')
  CURRENT_MIDNIGHT_DIFF=`expr $MIDNIGHT_TIME - $CUR_TIME`
  SLEEP_INTERVAL=`expr $CURRENT_MIDNIGHT_DIFF % $INTERVAL`
  
  if [ $SLEEP_INTERVAL -le 0 ]; then
    SLEEP_INTERVAL=$INTERVAL
  fi
  
  trace_log 2 "CUR_TIME = '$CUR_TIME' MIDNIGHT_TIME = '$MIDNIGHT_TIME' CURRENT_MIDNIGHT_DIFF = '$CURRENT_MIDNIGHT_DIFF' SLEEP_INTERVAL = '$SLEEP_INTERVAL'"
}

Usage()
{
  error_log "$*"
  error_log "Usage: cm_postgres_stats -u <User> p <Password> -d <Database name> -H <HOST/IP> -P <PORT> -i <interval in secs> -t <trace level>"
  exit -1
}

############# Function Calling ################################

#Must set trace/error log file in the beginning
set_up_env
set_error_and_trace_log_file

while getopts u:p:d:H:P:i:t: c  2>/dev/null
do
  case $c in
    u) USER=$OPTARG ;;
    p) PASSWORD=$OPTARG ;;   #In PGSQL password is not needed, postgres automatically provides password. Also on providing password
                             #explicitly there is overhead of making one extra connection because if password given then postgres creates one 
                             #connection only for password
    d) DATABASE_NAME=$OPTARG ;;
    H) HOST=$OPTARG ;;
    P) PORT=$OPTARG ;;
    i) INTERVAL=$OPTARG;;    #Default progress interval '10 sec'
    t) TRACE=$OPTARG;;       #Default 2
    ?) Usage "Invalid arguments";;
    *) Usage "Invalid arguments";;
  esac
done

check_mandatory_options

INTERVAL_IN_MIN=`awk -v "var1=$INTERVAL" 'BEGIN{printf "%f", (var1/60)}'`

#'ps -ef | grep postgres | grep "\-D"' OUTPUT
#postgres  4746     1  0 09:15 ?        00:00:01 /usr/lib/postgresql/9.1/bin/postgres -D /var/lib/pgsql/data -c config_file=/etc/postgresql/9.1/main/postgresql.conf
POSTGRES_PATH=`ps -ef | grep postgres | grep "\-D" | awk -F'-D' '{print $2}' | awk '{print $1}'`

trace_log 1 "USER = '$USER' PASSWORD = '$PASSWORD' DATABASE_NAME = '$DATABASE_NAME' HOST = '$HOST' PORT = '$PORT' INTERVAL = '$INTERVAL' TRACE = '$TRACE' INTERVAL_IN_MIN = '$INTERVAL_IN_MIN' POSTGRES_PATH = $POSTGRES_PATH"

make_query_psql

set_dbid
check_and_remove_files "exit"

if [ "X$MON_OPTION" = "X1" ];then
  trace_log 1 "Postgres stats monitor started."
  run_query_psql
  process_data
  display_data
  check_and_remove_files
else
  while true
  do
    # Test is over. So exit with success status
    isTestOver $MON_TEST_RUN
    if [ $? = 1 ]; then
      check_and_remove_files
      exit 0
    fi

    trace_log 1 "Postgress stats monitor started."
    run_query_psql
    process_data
    display_data
    check_and_remove_files
    calculate_sleep_interval
    trace_log 2 "Sleeping for $SLEEP_INTERVAL seconds"
    lib_sleep $SLEEP_INTERVAL
  done
fi
